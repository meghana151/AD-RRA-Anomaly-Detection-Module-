def build_autoencoder(input_shape, latent_dim=16):
    inputs = layers.Input(shape=input_shape)
    x = layers.Conv1D(32, 7, activation='relu', padding='same')(inputs)
    x = layers.MaxPooling1D(2)(x)
    x = layers.Conv1D(64, 5, activation='relu', padding='same')(x)
    x = layers.MaxPooling1D(2)(x)
    x = layers.Conv1D(128, 3, activation='relu', padding='same')(x)
    x = layers.MaxPooling1D(2)(x)
    shape_before_flatten = tf.keras.backend.int_shape(x)
    x = layers.Flatten()(x)
    latent = layers.Dense(latent_dim)(x)
    x = layers.Dense(np.prod(shape_before_flatten[1:]), activation='relu')(latent)
    x = layers.Reshape(shape_before_flatten[1:])(x)
    x = layers.UpSampling1D(2)(x)
    x = layers.Conv1D(128, 3, activation='relu', padding='same')(x)
    x = layers.UpSampling1D(2)(x)
    x = layers.Conv1D(64, 5, activation='relu', padding='same')(x)
    x = layers.UpSampling1D(2)(x)
    x = layers.Conv1D(32, 7, activation='relu', padding='same')(x)
    outputs = layers.Conv1D(1, 1, activation='linear', padding='same')(x)
    model = models.Model(inputs, outputs)
    model.compile(optimizer='adam', loss='mse')
    return model